#!/usr/bin/env bash
set -e

cd ~/RAGEN2/test2
export PYTHONPATH="$PWD:$PWD/verl"

export HF_DATASETS_CACHE="/projects/e32695/huggingface/datasets"
python train.py --config-name _11_deepcoder \
    model_path=/projects/e32695/huggingface/huggingface/hub/models--Qwen--Qwen3-4B-Thinking-2507/snapshots/768f209d9ea81521153ed38c47d515654e938aea \
    trainer.project_name=deepcoder_P1 \
    trainer.experiment_name=deepcoder_100turns_token_level_budget_token_estimation \
    trainer.total_training_steps=100 \
    ppo_mini_batch_size=4 \
    micro_batch_size_per_gpu=1 \
    es_manager.train.env_groups=4 es_manager.train.group_size=8 es_manager.train.env_configs.n_groups=[4] \
    es_manager.val.env_groups=4 es_manager.val.group_size=8 es_manager.val.env_configs.n_groups=[4] \
    system.CUDA_VISIBLE_DEVICES=\"0,1,2,3\" trainer.n_gpus_per_node=4 actor_rollout_ref.rollout.tensor_model_parallel_size=4 \
    trainer.save_freq=100 trainer.validation_steps=1 trainer.val_before_train=True \
    trainer.test_freq=20 \
    actor_rollout_ref.rollout.rollout_filter_ratio=0.5 \
    trainer.nnodes=1 \
    agent_proxy.max_turn=1 \
    agent_proxy.mixed_token_budget.enabled=True \
    agent_proxy.mixed_token_budget.mixed_budget=True \
    agent_proxy.mixed_token_budget.reward_curve.tau=1000 \
    agent_proxy.token_estimation=True \
    agent_proxy.mixed_token_budget.mixed_budget_range=[4000,5000] \
    actor_rollout_ref.actor.use_ref=False \
    actor_rollout_ref.rollout.max_model_len=18000 \
    actor_rollout_ref.rollout.max_num_batched_tokens=18000 \
    actor_rollout_ref.rollout.response_length=6000 \
    lora.rank=0 lora.alpha=64 lora.target_modules=all-linear \
    trainer.default_local_dir=/projects/e32695/checkpoints/deepcoder/100turns_token_level_budget_token_estimation \
    actor_rollout_ref.rollout.gpu_memory_utilization=0.7\
    trainer.resume_mode=disable